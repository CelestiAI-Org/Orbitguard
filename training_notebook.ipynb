{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Collision Risk AI - Time Series LSTM Tutorial\n",
                "\n",
                "This notebook demonstrates how to interact with the new Time-Series LSTM pipeline programmatically. We will load data, preprocess it into sequences, and inspect the model's behavior."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yaml\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from app.pipeline.datasource import JsonFileDataSource\n",
                "from app.pipeline.preprocessor import TimeSeriesPreprocessor\n",
                "from app.model.lstm_model import CollisionRiskLSTM, CertaintyEstimator"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Configuration and Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Config\n",
                "with open(\"config.yaml\", 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "print(f\"Loading data from: {config['data']['json_path']}\")\n",
                "source = JsonFileDataSource(config['data']['json_path'])\n",
                "raw_data = source.fetch_data()\n",
                "print(f\"Loaded {len(raw_data)} records.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocess into Sequences\n",
                "The preprocessor groups updates by (SAT1, SAT2, TCA) and creates time-series sequences."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "seq_len = config['model']['sequence_length']\n",
                "preprocessor = TimeSeriesPreprocessor(sequence_length=seq_len)\n",
                "sequences, targets = preprocessor.process(raw_data)\n",
                "\n",
                "print(f\"Generated {len(sequences)} sequences.\")\n",
                "print(f\"Sequence Shape: {sequences[0].shape}\")\n",
                "\n",
                "# Visualize a sample sequence\n",
                "sample_idx = 0\n",
                "print(\"Sample Sequence (PC, MinRng, TimeToTCA):\")\n",
                "print(sequences[sample_idx])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load Trained Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = CollisionRiskLSTM(\n",
                "    input_size=3,\n",
                "    hidden_size=config['model']['hidden_size'],\n",
                "    num_layers=config['model']['num_layers']\n",
                ")\n",
                "\n",
                "# Load weights (ensure you ran 'python main.py --mode train' first)\n",
                "try:\n",
                "    model.load_state_dict(torch.load(config['output']['model_path']))\n",
                "    model.eval()\n",
                "    print(\"Model loaded successfully.\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Model file not found! Please run training first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Analyze Predictions & Certainty"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'model' in locals():\n",
                "    X = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
                "    \n",
                "    # Get Prediction\n",
                "    with torch.no_grad():\n",
                "        preds = model(X).numpy()\n",
                "        \n",
                "    # Get Certainty (MC Dropout)\n",
                "    uncertainties = []\n",
                "    for i in range(10): # Analyzed first 10 for demo\n",
                "        cert = CertaintyEstimator.calculate_uncertainty(model, X[i:i+1])\n",
                "        uncertainties.append(cert)\n",
                "        \n",
                "    # Plot\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.plot(preds[:50], label='Predicted Risk')\n",
                "    plt.plot(targets[:50], label='Actual Risk', alpha=0.5)\n",
                "    plt.title(\"Risk Predictions vs Actuals (First 50)\")\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"Top 10 Certainty Scores:\", uncertainties)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}